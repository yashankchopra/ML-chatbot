{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Corpus that contains information to be used by our chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chopra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/chopra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f = open('chatbot.txt','r', errors ='ignore')\n",
    "raw_doc = f.read()\n",
    "raw_doc = raw_doc.lower()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw_doc)\n",
    "word_tokens = nltk.word_tokenize(raw_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"machine learning\\xa0(ml) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks.\",\n",
       " '[1]\\xa0it is seen as a part of\\xa0artificial intelligence.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine', 'learning']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def lemtokens (tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def lemnormalize(text):\n",
    "    return lemtokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Greeting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "greet_imputs = ('hello', 'hi', 'greetings','whatsup','hey', 'sup', \"what's up\", 'namaste')\n",
    "greet_response = ['Hi', 'Hey', 'Namaste!', 'Hi there', \"I am glad you're talking to me\", \"Hello! I hope this chatbot gets me hired!\"]\n",
    "\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greet_imputs:\n",
    "            return random.choice(greet_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response (user_response):\n",
    "    robo1_response = ''\n",
    "    TfidfVec= TfidfVectorizer(tokenizer=lemnormalize, stop_words='english')\n",
    "    Tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(Tfidf[-1], Tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response = robo1_response+sent_tokens[idx]\n",
    "        return robo1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: My Name is Stark. Let's have a conversation! If you want to exit, just type Bye!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:Hello! I hope this chatbot gets me hired!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is machine learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:[128][129]\n",
      "embedded machine learning\n",
      "embedded machine learning is a sub-field of machine learning, where the machine learning model is run on embedded systems with limited computing resources such as wearable computers, edge devices and microcontrollers.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is artificial intelligence \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:artificial intelligence is the simulation of human intelligence processes by machines, especially computer systems.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " can you tell me a list of ml algorithms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:list of popular machine learning algorithms\n",
      "linear regression.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " objective of machine learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is support vector machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:...\n",
      "svm (support vector machine) algorithm.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " svm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:...\n",
      "svm (support vector machine) algorithm.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is Reinforcement learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:[38]\n",
      "reinforcement learning\n",
      "main article: reinforcement learning\n",
      "reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: You are welcome..\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"Bot: My Name is Stark. Let's have a conversation! If you want to exit, just type Bye!\")\n",
    "while (flag==True):\n",
    "    user_response = input()\n",
    "    user_response = user_response.lower()\n",
    "    if (user_response != 'bye'):\n",
    "        if(user_response==\"thanks\" or user_response==\"thank you\"):\n",
    "            flag = False\n",
    "            print(\"Bot: You are welcome..\")\n",
    "        else:\n",
    "            if (greet(user_response) != None):\n",
    "                print(\"Bot:\" + greet(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
    "                final_words = list(set(word_tokens))\n",
    "                print(\"Bot:\", end = \"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Bot: Goodbye Take Care !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
